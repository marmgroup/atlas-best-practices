# Reducing data volume

## Thinning animal tracks

Most data at this stage is technically ‘clean’, yet its volume alone may pose challenges for older hardware (such as computers or storage) and software (data analysis functions) if these are not optimised for efficient computation. Examples in the R statistical environment favoured by movement ecologists (Joo et al. 2020) include the default function for importing data from a file read.csv, which is much slower than newer alternatives (such as data.table’s fread; Dowle et al. XXXX). This coupled with the requirement of uniform sampling intervals by many methods in the field (e.g. Hidden Markov Models from Michelot et al. 2016, and Step Selection Functions from Signer et al. 2019) makes evenly reducing data volumes worthwhile. The two approaches here are aggregation and resampling, and both begin with rounding the timestamp of the observations to the nearest multiple of the desired interval. When resampling the data, one position for each unique value of the rounded timestamp is retained, while aggregation involves computing the median of values at the positions sharing the same rounded timestamp. While the median aggregation method is less sensitive to position outliers than resampling, it may result in inappropriate fractional values for some position covariates (e.g. the number of base stations in ATLAS data), while others such as positioning error estimates cannot be aggregated using a simple median alone. It is thus advisable to evaluate whether position covariates will be required unaltered in further steps (e.g. positioning error for movement models), in which case resampling may be more appropriate, or whether it is more important to optimise the position estimate, for which aggregation may be better suited.

It is natural to consider evenly reducing data volume before implementing filters or smooths, since this is computationally more efficient than thinning after filtering-smoothing. While resampling data will preserve position covariates which may be passed to further filters, it may also sample outliers which could then be discarded by filters, resulting in uneven sampling once more. On the other hand, median aggregation may not correctly handle position covariates on which data can be filtered, rendering further filtering steps suspect. Even assuming median aggregation is applied to data without covariates, increasing the sampling interval by an order of magnitude or more (e.g. from 3 s to 30 s in ATLAS data) will result in significant underestimation of instantaneous speed (see Noonan et al. 2019). This could have knock-on effects on the efficacy of speed filters applied after aggregation, since the instantaneous speeds of point outliers or trajectory reflections may now be within the range of speeds realistically expected for the study species, making these artifacts more challenging to remove.
